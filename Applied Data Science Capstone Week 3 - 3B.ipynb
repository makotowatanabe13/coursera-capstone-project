{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Analyzing Stack Overflow Activity\n",
    "\n",
    "In our developer advocacy team we keep an eye out on what is happening on Stack Overflow (SO). Stack Overflow questions can provide valuable insights into what customers are struggeling with and how they are consuming our services.\n",
    "\n",
    "This notebook analyzes\n",
    "\n",
    "\n",
    "* Which runtime environment or programming language is most commonly referred to in questions for our offerings?\n",
    "* Which tags are most commonly used?\n",
    "\n",
    "\n",
    "\n",
    "## Load and clean the data\n",
    "\n",
    "As the data is stored in Cloudant, the first step is to load the data into the notebook and prepare it for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the required packages.\n",
    "\n",
    "Install or update missing packages with `!pip install --user <package>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\n",
      "  Downloading https://files.pythonhosted.org/packages/88/01/a37e827c2d80c6a754e40e99b9826d978b55254cc6c6672b5b08f2e18a7f/pyspark-2.4.0.tar.gz (213.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 213.4MB 4.8kB/s eta 0:00:01.9MB 58.5MB/s eta 0:00:019% |███████████████████████████████▊| 211.5MB 69.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting py4j==0.10.7 (from pyspark)\n",
      "  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n",
      "\u001b[K    100% |████████████████████████████████| 204kB 5.0MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
      "  Running setup.py bdist_wheel for pyspark ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/dsxuser/.cache/pip/wheels/cd/54/c2/abfcc942eddeaa7101228ebd6127a30dbdf903c72db4235b23\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.7 pyspark-2.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --user pyspark\n",
    "import pixiedust\n",
    "import pyspark.sql.functions as func\n",
    "import pyspark.sql.types as types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure database connectivity\n",
    "\n",
    "Customize this cell with your Cloudant/CouchDB connection information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {"collapsed" : True},
   "outputs": [],
   "source": [
    "# @hidden_cell\n",
    "# Enter your Cloudant host name\n",
    "host = '--myhostname--'\n",
    "# Enter your Cloudant user name\n",
    "username = '--myusername--'\n",
    "# Enter your Cloudant password\n",
    "password = '--mysecretpassword--'\n",
    "# Enter your source database name\n",
    "database = '--mydatabasename--'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load documents from the database\n",
    "\n",
    "Load the documents into an Apache Spark DataFrame and describe the data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no changes are required to this cell\n",
    "# obtain Spark SQL Context\n",
    "sqlContext = SQLContext(sc)\n",
    "# load data\n",
    "so_data = sqlContext.read.format(\"com.cloudant.spark\").\\\n",
    "                                 option(\"cloudant.host\", host).\\\n",
    "                                 option(\"cloudant.username\", username).\\\n",
    "                                 option(\"cloudant.password\", password).\\\n",
    "                                 load(database)              \n",
    "so_data.cache()                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug only\n",
    "so_data.printSchema()\n",
    "so_data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data\n",
    "\n",
    "Select data that's relevant to this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sodf = so_data.select(so_data.question.question_id.alias(\"id\"),\n",
    "                       so_data.question.owner.accept_rate.alias(\"accept_rate\"),\n",
    "                       so_data.question.owner.reputation.alias(\"reputation\"),\n",
    "                       so_data.question.owner.user_id.alias(\"user_id\"),\n",
    "                       so_data.question.answer_count.alias(\"answer_count\"), \n",
    "                       so_data.question.creation_date.alias(\"creation\"), \n",
    "                       so_data.question.closed_date.alias(\"closed\"),\n",
    "                       so_data.question.is_answered.alias(\"answered\"),\n",
    "                       so_data.question.score.alias(\"score\"),\n",
    "                       so_data.question.view_count.alias(\"views\"),\n",
    "                       so_data.question.title.alias(\"title\"),\n",
    "                       so_data.question.tags.alias(\"tags\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug only\n",
    "sodf.printSchema()\n",
    "#sodf.select(sodf.id, sodf.tags).head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify runtime environment or programming language\n",
    "Questions sometimes contain tags that might identify a programming language or runtime environment, such as `node.js` or `ios`. The following chart depicts correlations between our offerings and those tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only consider questions that contain one of these tags \n",
    "key_tags = [\"cloudant\", \"dashdb\"]\n",
    "# of the questions that meet the first condition only count those that also contain a tag that is associated with a programming language or runtime environment\n",
    "# the following curated list was obtained from https://meta.stackoverflow.com/tags; customize as needed\n",
    "env = [\"node.js\", \"java\", \"javascript\", \"python\", \"android\",\"php\", \"node-red\", \"cordova\" ,\"c#\", \"ios\", \"swift\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {
      "aggregation": "SUM",
      "clusterby": "env",
      "handlerId": "barChart",
      "keyFields": "key",
      "mpld3": "false",
      "orientation": "vertical",
      "rowCount": "100",
      "valueFields": "count"
     }
    }
   },
   "outputs": [],
   "source": [
    "# ---------------\n",
    "# prepare data\n",
    "# ---------------\n",
    "env_df = sodf.select(sodf.id, sodf.tags)\n",
    "\n",
    "def extractKeyTags(tags):\n",
    "    # input: [\"tag1\",\"tag2\", \"tag3\", ...]\n",
    "    # output: [\"key_tag1\",\"key_tag2\",...]\n",
    "    out = []\n",
    "    for tag in tags:\n",
    "        if tag in key_tags:\n",
    "            out.append(tag)\n",
    "    return out\n",
    "extractUDF = func.udf(lambda c: extractKeyTags(c), types.ArrayType(types.StringType()))\n",
    "env_df = env_df.withColumn(\"keys\", extractUDF(env_df.tags))\n",
    "env_df = env_df.select(env_df.id, func.explode(env_df.keys).alias(\"key\"), env_df.tags)\n",
    "env_df = env_df.select(env_df.id, env_df.key, func.explode(env_df.tags).alias(\"tag\"))\n",
    "env_df = env_df.filter(func.col(\"tag\").isin(env)).groupBy([\"key\",\"tag\"]).count().orderBy(\"count\", ascending = False).withColumnRenamed(\"tag\",\"env\")\n",
    "\n",
    "# +--------+----------+-----+\n",
    "# |     key|       env|count|\n",
    "# +--------+----------+-----+\n",
    "# |cloudant|   node.js|   73|\n",
    "# |cloudant|      java|   49|\n",
    "# | ...\n",
    "\n",
    "# ---------------\n",
    "# visualize data\n",
    "# ---------------\n",
    "#env_df.show()\n",
    "display(env_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generic tag associations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only consider questions that contain one of these tags \n",
    "key_tags = [\"dashdb\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {
      "aggregation": "SUM",
      "clusterby": "tag",
      "handlerId": "barChart",
      "keyFields": "key",
      "orientation": "vertical",
      "rendererId": "matplotlib",
      "rowCount": "100",
      "valueFields": "count"
     }
    }
   },
   "outputs": [],
   "source": [
    "# ---------------\n",
    "# prepare data\n",
    "# ---------------\n",
    "tag_df = sodf.select(sodf.id, sodf.tags)\n",
    "def extractKeyTags(tags):\n",
    "    # input: [\"tag1\",\"tag2\", \"tag3\", ...]\n",
    "    # output: [\"key_tag1\",\"key_tag2\",...]\n",
    "    out = []\n",
    "    for tag in tags:\n",
    "        if tag in key_tags:\n",
    "            out.append(tag)\n",
    "    return out\n",
    "extractUDF = func.udf(lambda c: extractKeyTags(c), types.ArrayType(types.StringType()))\n",
    "tag_df = tag_df.withColumn(\"key\", extractUDF(tag_df.tags))\n",
    "tag_df = tag_df.select(tag_df.id, func.explode(tag_df.key).alias(\"key\"), tag_df.tags)\n",
    "tag_df = tag_df.select(tag_df.id, tag_df.key, func.explode(tag_df.tags).alias(\"tag\"))\n",
    "tag_df = tag_df.filter(func.col(\"key\").isin(key_tags)).filter(\"key != tag\").groupBy([\"key\",\"tag\"]).count().orderBy(\"count\", ascending = False)\n",
    "\n",
    "# +--------+------------+-----+\n",
    "#      key|         tag|count|\n",
    "# +--------+------------+-----+\n",
    "# |cloudant|     couchdb|  190|\n",
    "# |cloudant| ibm-bluemix|  170|\n",
    "# |  ...\n",
    "\n",
    "# ---------------\n",
    "# visualize data\n",
    "# ---------------\n",
    "#tag_df.show()\n",
    "display(tag_df)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
